{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:39.110886Z",
     "start_time": "2021-05-11T18:28:38.421331Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "datadir = \"\"\n",
    "training_set = datadir + 'DR12Q-63000.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:40.307506Z",
     "start_time": "2021-05-11T18:28:40.296339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['FLUX', 'PLATE_F', 'PLATE_T', 'Z_DR12Q_VI', 'Z_PCA', 'Z_PIPE', 'Z_QN']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File(training_set, 'r') \n",
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:40.880829Z",
     "start_time": "2021-05-11T18:28:40.682217Z"
    }
   },
   "outputs": [],
   "source": [
    "X = f['FLUX'][()]  \n",
    "Y = f['Z_DR12Q_VI'][()]\n",
    "Z= f['Z_QN'][()]\n",
    "W= f['Z_PIPE'][()]\n",
    "S= f['Z_PCA'][()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:41.086684Z",
     "start_time": "2021-05-11T18:28:41.081546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63100, 2000), (63100, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:41.482472Z",
     "start_time": "2021-05-11T18:28:41.476879Z"
    }
   },
   "outputs": [],
   "source": [
    "#features = torch.Tensor(X).view(-1,4000)\n",
    "#labels = torch.Tensor(Y).view(-1,1)\n",
    "\n",
    "label_std = (Y.std()**1.0) \n",
    "label_mean = Y.mean() \n",
    "labels_norm = (Y - label_mean)/label_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:43.209186Z",
     "start_time": "2021-05-11T18:28:41.823171Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X ,labels_norm, test_size= 0.1,random_state = 42 )\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X ,Z, test_size= 0.1,random_state = 42 )\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X ,W, test_size= 0.1,random_state = 42 )\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X ,S, test_size= 0.1,random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:43.444751Z",
     "start_time": "2021-05-11T18:28:43.210956Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train=torch.Tensor(X_train).view(-1,2000)\n",
    "Y_train=torch.Tensor(Y_train).view(-1,1)\n",
    "X_test=torch.Tensor(X_test).view(-1,2000)\n",
    "Y_test=torch.Tensor(Y_test).view(-1,1)\n",
    "\n",
    "Y_test1=torch.Tensor(Y_test1).view(-1,1)\n",
    "Y_test2=torch.Tensor(Y_test2).view(-1,1)\n",
    "Y_test3=torch.Tensor(Y_test3).view(-1,1)\n",
    "\n",
    "#Z_test=torch.Tensor(Z_test).view(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:43.447838Z",
     "start_time": "2021-05-11T18:28:43.446209Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataset_train = TensorDataset(X_train, Y_train)\n",
    "#dataset_test = TensorDataset(X_test, Y_test)\n",
    "#dataset_QN = TensorDataset(X_test, Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:43.994613Z",
     "start_time": "2021-05-11T18:28:43.989671Z"
    }
   },
   "outputs": [],
   "source": [
    "#self.layer4 = nn.Sequential(\n",
    " #           nn.Conv1d(36, 20, 12),\n",
    " #           nn.ReLU(),\n",
    " #           nn.MaxPool1d(2, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:44.521560Z",
     "start_time": "2021-05-11T18:28:44.512007Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 60, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(60, 70,200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(70, 36, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(5724, 900),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(900, 100),\n",
    "            nn.ReLU())\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:45.076835Z",
     "start_time": "2021-05-11T18:28:45.067505Z"
    }
   },
   "outputs": [],
   "source": [
    "class FNet(nn.Module): #200-200-32\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FNet, self).__init__()\n",
    "        self.C1 = nn.Conv1d(1, 60, 200)\n",
    "        self.S2 = nn.MaxPool1d(2, stride=2)\n",
    "        self.C3 = nn.Conv1d(60, 40,200)\n",
    "        self.S4 = nn.MaxPool1d(2, stride=2)\n",
    "        self.C5 = nn.Conv1d(40, 36, 32)\n",
    "        self.S6 = nn.MaxPool1d(2, stride=2)\n",
    "        self.D7 = nn.Dropout()\n",
    "        self.F8 = nn.Linear(5724, 900)\n",
    "        self.F9= nn.Linear(900, 100)\n",
    "        self.Out= nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(self.C1(x))\n",
    "        x = self.S2(x)\n",
    "        x = F.relu(self.C3(x))\n",
    "        x = self.S4(x)\n",
    "        x = F.relu(self.C5(x))\n",
    "        x = self.S6(x)\n",
    "        x = self.D7(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.F8(x))\n",
    "        x = F.relu(self.F9(x))\n",
    "        x = self.Out(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T18:28:45.628975Z",
     "start_time": "2021-05-11T18:28:45.593338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(1, 60, kernel_size=(200,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(60, 70, kernel_size=(200,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv1d(70, 36, kernel_size=(32,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop_out): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=5724, out_features=900, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=900, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model= RNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:22:12.492704Z",
     "start_time": "2021-05-11T22:22:12.487221Z"
    }
   },
   "outputs": [],
   "source": [
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import LRScheduler\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "#from skorch.dataset import CVSplit\n",
    "net = NeuralNet(model,\n",
    "               criterion =nn.MSELoss,\n",
    "               max_epochs =3,\n",
    "               batch_size=100,\n",
    "                optimizer=torch.optim.Adam,\n",
    "                lr =0.00000104, #1:0.00004,\n",
    "                optimizer__weight_decay=1e-4,#0.0005,\n",
    "                #optimizer__epsilon=1e-08,\n",
    "                #optimizer__alpha=0.1,\n",
    "                optimizer__betas=(0.9, 0.99),\n",
    "               device ='cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:22:12.940781Z",
     "start_time": "2021-05-11T22:22:12.937006Z"
    }
   },
   "outputs": [],
   "source": [
    "#import gc\n",
    "\n",
    "#gc.collect()\n",
    "\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T22:22:13.260989Z",
     "start_time": "2021-05-11T22:22:13.257284Z"
    }
   },
   "outputs": [],
   "source": [
    "#from skorch import NeuralNet\n",
    "#from skorch.callbacks import LRScheduler\n",
    "#from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "#from skorch.dataset import CVSplit\n",
    "#net = NeuralNet(model,\n",
    " #              criterion =nn.MSELoss,\n",
    "  #             max_epochs =100,\n",
    "   #            batch_size=140,\n",
    "    #            optimizer=torch.optim.Adagrad,#torch.optim.Adam,\n",
    "     #           lr =0.00024,\n",
    "                #optimizer__betas=(0.9, 0.999),\n",
    "      #          optimizer__lr_decay=0.00001,\n",
    "       #         #optimizer__weight_decay=0.001,\n",
    "        #       device ='cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:56.235Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m0.0011\u001b[0m        \u001b[32m0.0071\u001b[0m  121.9816\n"
     ]
    }
   ],
   "source": [
    "net.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:56.529Z"
    }
   },
   "outputs": [],
   "source": [
    "#from skorch import NeuralNet\n",
    "#from skorch.dataset import CVSplit\n",
    "#net = NeuralNet(model,\n",
    " #              criterion =nn.MSELoss,\n",
    "  #             max_epochs =20,\n",
    "   #            batch_size=180,\n",
    "    #            optimizer=torch.optim.Adam,\n",
    "     #           lr =0.000000240,\n",
    "      #         device ='cuda') \n",
    "#net.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:56.796Z"
    }
   },
   "outputs": [],
   "source": [
    "#from skorch import NeuralNet\n",
    "#from skorch.dataset import CVSplit\n",
    "#net = NeuralNet(model,\n",
    " #              criterion =nn.MSELoss,\n",
    "  #             max_epochs =1,\n",
    "   #            batch_size=160,\n",
    "    #            optimizer=torch.optim.Adam,\n",
    "     #           lr =0.000000090,\n",
    "      #         device ='cuda') \n",
    "#net.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:57.017Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Losses =net.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:57.173Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_loss = net.history[:,'valid_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:57.324Z"
    }
   },
   "outputs": [],
   "source": [
    " train_loss = net.history[:,'train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:57.489Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('validaton loss, train loss')\n",
    "plt.plot(valid_loss)\n",
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:57.725Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = net.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:57.926Z"
    }
   },
   "outputs": [],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:58.553Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:36:58.893Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels_norm = (Y - label_mean)/label_std\n",
    "\n",
    "Z = Y_pred*label_std+label_mean\n",
    "y = Y_test*label_std+label_mean\n",
    "\n",
    "x1=np.linspace(0,7,9)\n",
    "y1=x1\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(y, Z, s=10, c='b', marker=\"s\")\n",
    "ax1.scatter(y, Y_test1, s=10, c='r', marker=\"s\")\n",
    "plt.plot(x1,y1)\n",
    "plt.xlabel('test')\n",
    "plt.ylabel('predicted redshift')\n",
    "plt.xlim(0.1,7.1)\n",
    "plt.ylim(0.0,7.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:37:00.285Z"
    }
   },
   "outputs": [],
   "source": [
    "REL=300000*(Z-y.numpy())/(1+y.numpy())\n",
    "REL1=300000*(Y_test1.numpy()-y.numpy())/(1+y.numpy())\n",
    "REL2=300000*(Y_test2.numpy()-y.numpy())/(1+y.numpy())\n",
    "REL3=300000*(Y_test3.numpy()-y.numpy())/(1+y.numpy())\n",
    "abs(REL).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T21:27:43.611900Z",
     "start_time": "2021-05-05T21:27:43.606975Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:37:03.332Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(REL1)):\n",
    "    if ((abs(REL[i])<6000)):\n",
    "        print(i, file=open(\"Rahim.txt\", \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:37:03.711Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('Rahim.txt', \"r+\")\n",
    "file.truncate()\n",
    "for i in range(len(REL)):\n",
    "    if ((y.numpy()[i]>2.0)):\n",
    "        print(i, file=open(\"Rahim.txt\", \"a\"))\n",
    "        \n",
    "with open(\"Rahim.txt\",\"r\") as f:\n",
    "    print(len(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:37:06.528Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('Rahim.txt', \"r+\")\n",
    "file.truncate()\n",
    "for i in range(len(REL)):\n",
    "    if ((abs(REL[i])<6000)):\n",
    "        print(i, file=open(\"Rahim.txt\", \"a\"))\n",
    "        \n",
    "with open(\"Rahim.txt\",\"r\") as f:\n",
    "    print(len(f.readlines())/len(REL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T23:38:13.475Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "#pyplot.yscale('log')\n",
    "data = REL\n",
    "plt.figure(figsize=(8,10))\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "plt.hist(data, bins=10000,histtype='step',alpha=0.3,edgecolor='r',linewidth=2,label='FNet',color = 'blue')\n",
    "plt.hist(REL1, bins=10000,histtype='step',alpha=0.3,edgecolor='b',linewidth=2,label='QuasarNet')\n",
    "#plt.hist(REL2, bins=6000,histtype='step',alpha=0.3,edgecolor='g',linewidth=2,label='ZPIPW')\n",
    "plt.hist(REL3, bins=10000,histtype='step',alpha=0.3,edgecolor='black',linewidth=2,label='PCA')\n",
    "\n",
    "plt.ylabel('QSO number', fontsize=20)\n",
    "plt.yticks(fontsize=20) \n",
    "\n",
    "plt.xlabel(' ∆ν', fontsize=20)\n",
    "plt.xticks(fontsize=20) \n",
    "\n",
    "\n",
    "plt.xlim(-6000,6000)\n",
    "plt.legend(loc='best', fontsize=20) \n",
    "#plt.ylim(0,7)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T21:59:32.338784Z",
     "start_time": "2021-05-11T21:59:32.329377Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Rahim1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ae46a75307a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Rahim1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rahim1.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Rahim1.txt'"
     ]
    }
   ],
   "source": [
    "file = open('Rahim1.txt', \"r+\")\n",
    "file.truncate()\n",
    "for i in range(len(REL)):\n",
    "    if ((abs(REL[i])>6000)):\n",
    "        print(REL[i], file=open(\"Rahim1.txt\", \"a\"))\n",
    "with open(\"Rahim1.txt\",\"r\") as f:\n",
    "    print(1-len(f.readlines())/len(REL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-11T19:43:37.713Z"
    }
   },
   "outputs": [],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:05:06.377187Z",
     "start_time": "2021-05-11T08:51:52.265Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 20, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(20, 20,200),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(20, 36, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(12600, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:07:46.201349Z",
     "start_time": "2021-05-10T19:55:08.619Z"
    }
   },
   "outputs": [],
   "source": [
    "from skorch import NeuralNet\n",
    "from skorch.callbacks import LRScheduler\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "#from skorch.dataset import CVSplit\n",
    "net = NeuralNet(model,\n",
    "               criterion =nn.MSELoss,\n",
    "               max_epochs =2,\n",
    "               batch_size=110,\n",
    "                optimizer=torch.optim.SGD,\n",
    "                callbacks=[\n",
    "        ('lr_scheduler',\n",
    "         LRScheduler(policy=CyclicLR,\n",
    "                     base_lr=0.000001,\n",
    "                     max_lr=0.0001)),\n",
    "    ],\n",
    "               device ='cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
